# **ğŸ¨ Landscape Sketch to Paint: U-Net ve Pix2Pix GAN ile GÃ¶rÃ¼ntÃ¼ Sentezi**

**Ders:** Derin Ã–ÄŸrenme (Deep Learning) DÃ¶nem Projesi

**Konu:** Image-to-Image Translation (GÃ¶rÃ¼ntÃ¼den GÃ¶rÃ¼ntÃ¼ye Ã‡eviri)

**Model YaklaÅŸÄ±mÄ±:** AÅŸamalÄ± GeliÅŸtirme (Baseline U-Net \-\> Final Pix2Pix GAN)

**EÄŸitim DonanÄ±mÄ±:** NVIDIA Tesla T4 GPU

ğŸ”— **CanlÄ± Demo UygulamasÄ±:** [Streamlit Ãœzerinde GÃ¶rÃ¼ntÃ¼le](https://landscape-sketch-to-paint-8jikjxxn4lxsqcxfcebwpr.streamlit.app/)

ğŸ”— **Veri Seti:** [Kaggle \- Landscape Pictures](https://www.kaggle.com/datasets/arnaud58/landscape-pictures)

## ğŸ“„ Proje Raporu

Projenin teknik detaylarÄ±nÄ±, model mimarisini ve deneysel sonuÃ§larÄ±nÄ± iÃ§eren
detaylÄ± raporu incelemek iÃ§in aÅŸaÄŸÄ±daki baÄŸlantÄ±ya tÄ±klayabilirsiniz:

[ğŸ‘‰ Proje Raporunu GÃ¶rÃ¼ntÃ¼le (PDF)](Rapor.pdf)

<img width="1635" height="929" alt="Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2025-12-30 015604" src="https://github.com/user-attachments/assets/656cf571-01f4-4fe8-accc-230ceeed0a1f" />


## 1. Proje Konusu ve SeÃ§ilme GerekÃ§esi 

### **Problem TanÄ±mÄ±**

Bu proje, bilgisayarlÄ± gÃ¶rÃ¼ (Computer Vision) alanÄ±nda **"Image Synthesis"** problemini ele alÄ±r. Temel amaÃ§, kullanÄ±cÄ±nÄ±n girdiÄŸi basit siyah-beyaz Ã§izimleri (eskiz/sketch); anlamsal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ koruyarak gerÃ§ekÃ§i doku, renk ve Ä±ÅŸÄ±klandÄ±rmaya sahip manzara fotoÄŸraflarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmektir.

### **Projenin Ã–nemi ve LiteratÃ¼rdeki Yeri**

Dijital sanat Ã¼retimi, oyun geliÅŸtirme (prosedÃ¼rel iÃ§erik Ã¼retimi) ve mimari gÃ¶rselleÅŸtirme alanlarÄ±nda konsept tasarÄ±mlarÄ±n nihai gÃ¶rsele dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi bÃ¼yÃ¼k bir iÅŸ yÃ¼kÃ¼dÃ¼r. Geleneksel KonvolÃ¼syonel Sinir AÄŸlarÄ± (CNN), piksel hatalarÄ±nÄ± minimize etmeye Ã§alÄ±ÅŸÄ±rken (L1/L2 Loss) genellikle **bulanÄ±k (blurry)** sonuÃ§lar Ã¼retir.

Bu proje, **Generative Adversarial Networks (GAN)** yapÄ±larÄ±nÄ±n bu bulanÄ±klÄ±k sorununu nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼ gÃ¶stermek ve literatÃ¼rde devrim yaratan **Pix2Pix** (Isola et al., 2017\) mimarisinin uÃ§tan uca bir uygulamasÄ±nÄ± gerÃ§ekleÅŸtirmek amacÄ±yla seÃ§ilmiÅŸtir.

## 2. Veri Seti ve Ã–n Ä°ÅŸleme SÃ¼reÃ§leri 

Projede Kaggle platformunda bulunan **Landscape Pictures** veri seti kullanÄ±lmÄ±ÅŸtÄ±r. Ancak veri seti doÄŸrudan kullanÄ±lmamÄ±ÅŸ, **dinamik bir Ã¶n iÅŸleme hattÄ±ndan (preprocessing pipeline)** geÃ§irilmiÅŸtir.

### 2.1. Dinamik Veri Ãœretimi (Runtime Sketch Generation)

Projede hazÄ±r "sketch" verileri yerine, renkli fotoÄŸraflardan Ã§alÄ±ÅŸma zamanÄ±nda taslak Ã¼reten bir yapÄ± kurulmuÅŸtur. Bu iÅŸlem iÃ§in **OpenCV Canny Edge Detection** algoritmasÄ± kullanÄ±lmÄ±ÅŸtÄ±r.

* **AvantajÄ±:** Modelin farklÄ± kalem kalÄ±nlÄ±klarÄ±na ve Ã§izim stillerine karÅŸÄ± daha dayanÄ±klÄ± (robust) olmasÄ±nÄ± saÄŸlar.

\# Proje kodundan Ã¶rnek (Sketch Ãœretimi):  
gray \= cv2.cvtColor(img, cv2.COLOR\_RGB2GRAY)  
edges \= cv2.Canny(gray, 100, 200\) \# Girdi (Input) Ã§alÄ±ÅŸma anÄ±nda Ã¼retilir

### 2.2. Teknik KÄ±sÄ±tlamalar ve Optimizasyon

EÄŸitim sÃ¼reci Kaggle Kernel ortamÄ±nda (Tesla T4 GPU \- 16GB VRAM) gerÃ§ekleÅŸtirilmiÅŸtir. GAN eÄŸitimi, aynÄ± anda iki modelin (Generator \+ Discriminator) aÄŸÄ±rlÄ±klarÄ±nÄ± ve gradyanlarÄ±nÄ± bellekte tuttuÄŸu iÃ§in standart CNN'lere gÃ¶re 2 kat daha fazla VRAM gerektirir. ResourceExhaustedError sorununu aÅŸmak iÃ§in ÅŸu optimizasyonlar uygulanmÄ±ÅŸtÄ±r:

1. **Veri KÄ±sÄ±tlamasÄ± (Data Culling):** Toplam veri seti iÃ§erisinden rastgele seÃ§im yapÄ±larak eÄŸitim 2.500 gÃ¶rÃ¼ntÃ¼ ile sÄ±nÄ±rlandÄ±rÄ±lmÄ±ÅŸtÄ±r.  
2. **RAM YÃ¶netimi (Garbage Collection):** Python gc modÃ¼lÃ¼ kullanÄ±larak, iÅŸlenen ham veriler (del X\_full) bellekten manuel olarak temizlenmiÅŸtir.  
3. **Normalizasyon:** GÃ¶rÃ¼ntÃ¼ pikselleri, Generator Ã§Ä±kÄ±ÅŸÄ±ndaki Sigmoid aktivasyonuna uygun olarak $\[0, 1\]$ aralÄ±ÄŸÄ±na normalize edilmiÅŸtir (img / 255.0).  
4. **Veri AyrÄ±mÄ±:** Veri seti karÄ±ÅŸtÄ±rÄ±larak (shuffle) %90 EÄŸitim, %10 DoÄŸrulama olarak ayrÄ±lmÄ±ÅŸtÄ±r.

## 3. YÃ¶ntem SeÃ§imi ve KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz 

Proje kapsamÄ±nda problem Ã§Ã¶zÃ¼mÃ¼ne aÅŸamalÄ± bir yaklaÅŸÄ±m izlenmiÅŸ ve iki farklÄ± deney gerÃ§ekleÅŸtirilmiÅŸtir.

### 3.1. Deneysel SÃ¼reÃ§ 1: Baseline Model (Sadece U-Net)

* **Ä°lgili Dosya:** notebooks/Training\_UNet.ipynb

Ä°lk aÅŸamada, problemin sadece piksel tabanlÄ± bir regresyon problemi olarak Ã§Ã¶zÃ¼lÃ¼p Ã§Ã¶zÃ¼lemeyeceÄŸi test edilmiÅŸtir.

* **YÃ¶ntem:** Standart U-Net mimarisine ek olarak her katmanda Batch Normalization kullanÄ±larak eÄŸitim stabilize edilmiÅŸtir.  
* **KayÄ±p Fonksiyonu:** L1 Loss (Mean Absolute Error).  
* **SonuÃ§ Analizi:** Model nesnelerin yerini doÄŸru Ã¶ÄŸrense de, dokular (Ã§imen, kaya yÃ¼zeyi) pÃ¼rÃ¼zsÃ¼z ve bulanÄ±k (blurry) Ã§Ä±kmÄ±ÅŸtÄ±r.  
* **Nedeni:** L1 kaybÄ±, belirsizlik durumunda olasÄ± tÃ¼m renklerin "ortalamasÄ±nÄ±" almayÄ± tercih eder.

### 3.2. Deneysel SÃ¼reÃ§ 2: Final Model (Pix2Pix GAN)

* **Ä°lgili Dosya:** notebooks/Training\_Pix2Pix\_GAN.ipynb

BulanÄ±klÄ±k sorununu Ã§Ã¶zmek iÃ§in sisteme Adversarial Learning (Ã‡ekiÅŸmeli Ã–ÄŸrenme) eklenmiÅŸtir.

* **YÃ¶ntem:** KoÅŸullu GAN (cGAN) yapÄ±sÄ± kurulmuÅŸtur.  
* **Discriminator (EleÅŸtirmen):** GÃ¶rÃ¼ntÃ¼nÃ¼n tamamÄ±na tek puan vermek yerine, resmi $30 \\times 30$ boyutunda yamalara bÃ¶len **PatchGAN** kullanÄ±lmÄ±ÅŸtÄ±r. Bu, modelin yÃ¼ksek frekanslÄ± detaylarÄ± (keskinliÄŸi) Ã¶ÄŸrenmesini zorunlu kÄ±lar.  
* **SonuÃ§ Analizi:** SonuÃ§lar Ã§ok daha keskin, detaylÄ± ve gerÃ§ekÃ§idir.

## 4. Model EÄŸitimi ve Mimari Detaylar 

AÅŸaÄŸÄ±daki tablo, iki aÅŸama arasÄ±ndaki teknik farklarÄ± Ã¶zetlemektedir:

| Ã–zellik | 1\. AÅŸama (Baseline U-Net) | 2\. AÅŸama (Pix2Pix GAN) |
| :---- | :---- | :---- |
| **Model YapÄ±sÄ±** | U-Net \+ Batch Norm | U-Net (Gen) \+ PatchGAN (Disc) |
| **Parametre SayÄ±sÄ±** | \~31 Milyon | \~54 Milyon (Gen) \+ \~2.7 Milyon (Disc) |
| **KayÄ±p Fonksiyonu** | L1 Loss (MAE) | Adversarial Loss \+ (100 \* L1 Loss) |
| **Optimizer** | Adam (LR=0.001) | Adam (LR=0.0002, Beta1=0.5) |
| **Batch Size** | 32 | 4 (VRAM Optimizasyonu) |
| **Epochs** | 37 (Early Stopping) | 30 |
| **Aktivasyon (Ã‡Ä±kÄ±ÅŸ)** | Sigmoid | Sigmoid |
| **Ã–zel Teknikler** | ReduceLROnPlateau | Custom Training Loop, GANMonitor |

### 4.1. Generator Mimarisi (Ortak)

Her iki deneyde de Generator olarak **U-Net** kullanÄ±lmÄ±ÅŸtÄ±r.

* **Encoder:** GÃ¶rÃ¼ntÃ¼yÃ¼ sÄ±kÄ±ÅŸtÄ±rarak Ã¶znitelikleri Ã§Ä±karÄ±r.  
* **Decoder:** GÃ¶rÃ¼ntÃ¼yÃ¼ tekrar geniÅŸletir.  
* **Skip Connections:** Encoder'daki kenar bilgilerini doÄŸrudan Decoder'a taÅŸÄ±yarak taslaÄŸÄ±n ÅŸeklinin korunmasÄ±nÄ± saÄŸlar.

### 4.2. Discriminator Mimarisi (PatchGAN)

Sadece GAN aÅŸamasÄ±nda kullanÄ±lmÄ±ÅŸtÄ±r. GÃ¶rÃ¼ntÃ¼yÃ¼ $30 \\times 30$ boyutunda yamalara bÃ¶ler ve her yama iÃ§in "GerÃ§ek" veya "Sahte" kararÄ± verir.

### 4.3. KayÄ±p FonksiyonlarÄ±

$$ Total Loss \= Loss\_{GAN} \+ (\\lambda \\times Loss\_{L1}) $$

* **Adversarial Loss:** Discriminator'Ä± kandÄ±rma baÅŸarÄ±sÄ± (GerÃ§ekÃ§ilik).  
* **L1 Loss:** Piksel bazlÄ± benzerlik (Renk DoÄŸruluÄŸu). $\\lambda \= 100$ katsayÄ±sÄ± ile aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸtÄ±r.

## 5. SonuÃ§larÄ±n DeÄŸerlendirilmesi

### 5.1. SayÄ±sal Analiz (Metrics)

Modelin baÅŸarÄ±sÄ± test seti Ã¼zerinde SSIM ve PSNR metrikleri ile Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r:

* **Ortalama PSNR:** 17.93 dB  
* **Ortalama SSIM:** 0.5333

**Yorum:** Bu deÄŸerlerin "mÃ¼kemmel" (SSIM \> 0.8) sÄ±nÄ±rÄ±nÄ±n altÄ±nda kalmasÄ±nÄ±n temel nedeni **Mevsimsel Belirsizliktir (Multimodality)**. Siyah-beyaz bir aÄŸaÃ§ Ã§izimi, "Sonbahar (Turuncu)" veya "Ä°lkbahar (YeÅŸil)" olarak yorumlanabilir. Model gÃ¶rsel olarak baÅŸarÄ±lÄ± olsa bile, orijinal fotoÄŸraftan farklÄ± bir mevsim/renk seÃ§tiÄŸinde piksel tabanlÄ± metrikler matematiksel olarak dÃ¼ÅŸÃ¼k Ã§Ä±kmaktadÄ±r.

### 5.2. GÃ¶rsel Analiz (Visual Inspection)

* **U-Net SonuÃ§larÄ±:** YapÄ±sal olarak doÄŸru ancak "sulu boya" etkisi yaratan bulanÄ±k sonuÃ§lar.  
* **GAN SonuÃ§larÄ±:** Nehir yansÄ±malarÄ±, bulut dokularÄ± ve daÄŸ yÃ¼zeylerinde belirgin keskinlik artÄ±ÅŸÄ±. AyrÄ±ca EÄŸitim sÄ±rasÄ±nda GANMonitor callback'i ile her epoch sonunda Ã¼retilen gÃ¶rsellerdeki geliÅŸim net bir ÅŸekilde gÃ¶zlemlenmiÅŸtir.

## 6. Proje DokÃ¼mantasyonu ve Dosya YapÄ±sÄ± 

Proje dosyalarÄ±, yeniden Ã¼retilebilirlik (reproducibility) ilkesine uygun olarak, kodun modÃ¼lerliÄŸini ve okunabilirliÄŸini artÄ±racak ÅŸekilde organize edilmiÅŸtir. AÅŸaÄŸÄ±da dizin yapÄ±sÄ± ve dosyalarÄ±n iÅŸlevleri detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r:

```text
Landscape-Sketch-to-Paint/
â”œâ”€â”€ app.py                     # Streamlit web arayÃ¼zÃ¼ ana Ã§alÄ±ÅŸtÄ±rma dosyasÄ±
â”œâ”€â”€ requirements.txt           # Proje iÃ§in gerekli Python kÃ¼tÃ¼phaneleri ve sÃ¼rÃ¼mleri
â”œâ”€â”€ style_utils.py             # ArayÃ¼z iÃ§in Ã¶zel CSS ve HTML tasarÄ±m kodlarÄ±
â”œâ”€â”€ src/                       # Kaynak Kodlar (ModÃ¼ler Mimari)
â”‚   â”œâ”€â”€ model.py               # U-Net ve GAN (Generator/Discriminator) mimari tanÄ±mlarÄ±
â”‚   â””â”€â”€ __init__.py            # KlasÃ¶rÃ¼n Python paketi olarak tanÄ±nmasÄ±nÄ± saÄŸlar
â”œâ”€â”€ notebooks/                 # Model EÄŸitim SÃ¼reÃ§leri (KanÄ±t DosyalarÄ±)
â”‚   â”œâ”€â”€ Training_UNet.ipynb        # 1. AÅŸama: Baseline U-Net deneyleri ve sonuÃ§larÄ±
â”‚   â””â”€â”€ Training_Pix2Pix_GAN.ipynb # 2. AÅŸama: Final Pix2Pix GAN modelinin eÄŸitimi
â”œâ”€â”€ examples/                  # Test ve demo iÃ§in kullanÄ±lan Ã¶rnek taslak gÃ¶rselleri
â”œâ”€â”€ models/                    # (Otomatik oluÅŸturulur) EÄŸitilmiÅŸ aÄŸÄ±rlÄ±k dosyalarÄ±nÄ±n indiÄŸi klasÃ¶r
â””â”€â”€ README.md                  # Proje teknik raporu ve kurulum kÄ±lavuzu

```
## 7. Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsiniz:

1.  **Depoyu klonlayÄ±n:**
    ```bash
    git clone https://github.com/Fatmanurkntr/Landscape-Sketch-to-Paint.git
    cd Landscape-Sketch-to-Paint
    ```

2.  **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **UygulamayÄ± baÅŸlatÄ±n:**
    ```bash
    streamlit run app.py
    ```
    *(Not: Uygulama ilk aÃ§Ä±lÄ±ÅŸta Google Drive entegrasyonu sayesinde eÄŸitilmiÅŸ model dosyalarÄ±nÄ± otomatik olarak indirecektir. Bu iÅŸlem internet hÄ±zÄ±nÄ±za baÄŸlÄ± olarak birkaÃ§ dakika sÃ¼rebilir.)*

    
## **8\. Referanslar**

1. Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. *Proceedings of the IEEE conference on computer vision and pattern recognition*.  
2. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. *MICCAI*.  
3. TensorFlow Core Tutorials: Pix2Pix.
