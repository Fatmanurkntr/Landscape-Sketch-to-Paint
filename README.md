# ğŸ¨ Landscape Sketch to Paint: U-Net ve Pix2Pix GAN ile GÃ¶rÃ¼ntÃ¼ Sentezi

**Ders:** Derin Ã–ÄŸrenme (Deep Learning) DÃ¶nem Projesi


**Konu:** Image-to-Image Translation (GÃ¶rÃ¼ntÃ¼den GÃ¶rÃ¼ntÃ¼ye Ã‡eviri)


**Model YaklaÅŸÄ±mÄ±:** AÅŸamalÄ± GeliÅŸtirme (Baseline U-Net -> Final Pix2Pix GAN)

ğŸ”— **CanlÄ± Demo UygulamasÄ±:** [Streamlit Ãœzerinde GÃ¶rÃ¼ntÃ¼le](https://landscape-sketch-to-paint-8jikjxxn4lxsqcxfcebwpr.streamlit.app/)

ğŸ”— **Veri Seti:** [Kaggle - Landscape Pictures](https://www.kaggle.com/datasets/arnaud58/landscape-pictures)

---

## 1. Proje Konusu ve SeÃ§ilme GerekÃ§esi

### Problem TanÄ±mÄ±
Bu proje, bilgisayarlÄ± gÃ¶rÃ¼ (Computer Vision) alanÄ±nda "Image Synthesis" olarak bilinen problemi ele alÄ±r. Temel amaÃ§, az bilgi iÃ§eren giriÅŸ verilerini (siyah-beyaz taslaklar/kenar haritalarÄ±), yÃ¼ksek frekanslÄ± detaylara sahip fotorealistik gÃ¶rÃ¼ntÃ¼lere (manzara fotoÄŸraflarÄ±) dÃ¶nÃ¼ÅŸtÃ¼rmektir. Proje, kullanÄ±cÄ±nÄ±n Ã§izdiÄŸi basit daÄŸ, nehir veya aÄŸaÃ§ sÄ±nÄ±rlarÄ±nÄ± algÄ±layarak; bu alanlarÄ± anlamsal bÃ¼tÃ¼nlÃ¼ÄŸe uygun doku, renk ve Ä±ÅŸÄ±klandÄ±rma ile doldurmayÄ± hedefler.

### Projenin Ã–nemi ve LiteratÃ¼rdeki Yeri
Dijital sanat Ã¼retimi, oyun geliÅŸtirme (prosedÃ¼rel iÃ§erik Ã¼retimi) ve mimari gÃ¶rselleÅŸtirme alanlarÄ±nda, konsept tasarÄ±mlarÄ±n nihai gÃ¶rsele dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi ciddi bir iÅŸ yÃ¼kÃ¼ oluÅŸturur. Geleneksel yÃ¶ntemler manuel boyama gerektirirken, **Generative Adversarial Networks (GAN)** tabanlÄ± yaklaÅŸÄ±mlar bu sÃ¼reci otomatize eder.
Bu proje, literatÃ¼rde devrim yaratan **Pix2Pix** (Isola et al., 2017) mimarisinin pratik bir uygulamasÄ±nÄ± sunmak, geleneksel KonvolÃ¼syonel Sinir AÄŸlarÄ± (CNN) ile GAN tabanlÄ± yaklaÅŸÄ±mlarÄ± karÅŸÄ±laÅŸtÄ±rmalÄ± olarak analiz etmek amacÄ±yla seÃ§ilmiÅŸtir.

---

## 2. Veri Seti ve Ã–n Ä°ÅŸleme SÃ¼reÃ§leri

Projede Kaggle platformunda bulunan **Landscape Pictures** veri seti kullanÄ±lmÄ±ÅŸtÄ±r. Veri seti, gerÃ§ek doÄŸa fotoÄŸraflarÄ±nÄ± ve bu fotoÄŸraflardan algoritmik yÃ¶ntemlerle (Canny Edge Detection vb.) tÃ¼retilmiÅŸ kenar haritalarÄ±nÄ± (sketch) iÃ§erir.

### Teknik KÄ±sÄ±tlamalar ve Optimizasyon
EÄŸitim sÃ¼reci **Kaggle Kernel** ortamÄ±nda (Tesla P100 GPU - 16GB VRAM) gerÃ§ekleÅŸtirilmiÅŸtir. Orijinal veri setinde 3.500'den fazla gÃ¶rÃ¼ntÃ¼ Ã§ifti bulunmaktadÄ±r. Ancak GAN mimarisinin, standart bir CNN'e gÃ¶re yaklaÅŸÄ±k 2 kat daha fazla bellek gerektirmesi (Generator + Discriminator + Gradient Tape hesaplamalarÄ±nÄ±n VRAM Ã¼zerinde tutulmasÄ±) nedeniyle `ResourceExhaustedError` (RAM TaÅŸmasÄ±) sorunu yaÅŸanmÄ±ÅŸtÄ±r.

EÄŸitimi stabilize etmek ve donanÄ±m limitleri dahilinde en iyi sonucu almak iÃ§in aÅŸaÄŸÄ±daki optimizasyon stratejileri uygulanmÄ±ÅŸtÄ±r:

1.  **Veri Seti Alt Ã–rnekleme (Random Subsampling):** Bellek yÃ¶netimini saÄŸlamak amacÄ±yla veri seti iÃ§erisinden rastgele seÃ§im yapÄ±larak eÄŸitim seti **2.500 gÃ¶rÃ¼ntÃ¼ Ã§iftine** indirilmiÅŸtir.
2.  **Yeniden BoyutlandÄ±rma (Resizing):** TÃ¼m giriÅŸ (sketch) ve Ã§Ä±kÄ±ÅŸ (photo) gÃ¶rÃ¼ntÃ¼leri $256 \times 256$ piksel boyutuna sabitlenmiÅŸtir.
3.  **Normalizasyon:** GÃ¶rÃ¼ntÃ¼ pikselleri, Generator modelinin Ã§Ä±kÄ±ÅŸ katmanÄ±ndaki `Tanh` aktivasyon fonksiyonunun Ã§alÄ±ÅŸma aralÄ±ÄŸÄ±na uygun olmasÄ± iÃ§in $[0, 255]$ aralÄ±ÄŸÄ±ndan $[-1, 1]$ aralÄ±ÄŸÄ±na normalize edilmiÅŸtir.
4.  **Veri AyrÄ±mÄ±:** Veri seti %80 EÄŸitim, %20 Test olacak ÅŸekilde ayrÄ±lmÄ±ÅŸtÄ±r.

---

## 3. YÃ¶ntem SeÃ§imi ve KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz (Deneysel SÃ¼reÃ§)

Proje kapsamÄ±nda problem Ã§Ã¶zÃ¼mÃ¼ne **aÅŸamalÄ±** bir yaklaÅŸÄ±m izlenmiÅŸ ve iki farklÄ± deney gerÃ§ekleÅŸtirilmiÅŸtir. Bu deneyler, kayÄ±p fonksiyonlarÄ±nÄ±n gÃ¶rÃ¼ntÃ¼ kalitesi Ã¼zerindeki etkisini gÃ¶stermektedir.

### 3.1. Deneysel SÃ¼reÃ§ 1: Baseline Model (Sadece U-Net)
**Ä°lgili Dosya:** `notebooks/Training_UNet.ipynb`

Ä°lk aÅŸamada, problemin sadece piksel tabanlÄ± bir regresyon problemi olarak Ã§Ã¶zÃ¼lÃ¼p Ã§Ã¶zÃ¼lemeyeceÄŸi test edilmiÅŸtir.
* **YÃ¶ntem:** Standart bir U-Net mimarisi (Encoder-Decoder + Skip Connections) kurulmuÅŸtur.
* **KayÄ±p Fonksiyonu:** L1 Loss (Mean Absolute Error). Model, `|GerÃ§ek - Tahmin|` farkÄ±nÄ± minimize etmeye odaklanmÄ±ÅŸtÄ±r.
* **SonuÃ§ Analizi:** Model, taslaÄŸÄ±n sÄ±nÄ±rlarÄ±nÄ± (daÄŸlarÄ±n ÅŸeklini, nehrin yolunu) Ã¶ÄŸrenmede baÅŸarÄ±lÄ± olmuÅŸtur. Ancak Ã¼retilen gÃ¶rseller **bulanÄ±k (blurry)** ve dokusuzdur.
* **Nedeni:** L1 kaybÄ±, belirsizlik durumunda olasÄ± tÃ¼m renklerin "ortalamasÄ±nÄ±" almaya meyillidir. Bu durum, Ã§im veya kaya gibi yÃ¼ksek frekanslÄ± detaylarÄ±n kaybolmasÄ±na neden olur.

### 3.2. Deneysel SÃ¼reÃ§ 2: Final Model (Pix2Pix GAN)
**Ä°lgili Dosya:** `notebooks/Training_Pix2Pix_GAN.ipynb`

BulanÄ±klÄ±k sorununu Ã§Ã¶zmek iÃ§in sisteme "Adversarial Learning" (Ã‡ekiÅŸmeli Ã–ÄŸrenme) mekanizmasÄ± eklenmiÅŸtir.
* **YÃ¶ntem:** KoÅŸullu GAN (cGAN) yapÄ±sÄ± kurulmuÅŸtur.
* **Discriminator (AyÄ±rt Edici):** GÃ¶rÃ¼ntÃ¼nÃ¼n tamamÄ±na tek bir puan vermek yerine, gÃ¶rÃ¼ntÃ¼yÃ¼ kÃ¼Ã§Ã¼k yamalara (patch) bÃ¶lerek inceleyen **PatchGAN** kullanÄ±lmÄ±ÅŸtÄ±r.
* **SonuÃ§ Analizi:** PatchGAN, modelin sadece renkleri deÄŸil, yerel doku tutarlÄ±lÄ±ÄŸÄ±nÄ± (keskinliÄŸi) da Ã¶ÄŸrenmesini zorunlu kÄ±lmÄ±ÅŸtÄ±r. SonuÃ§lar Ã§ok daha gerÃ§ekÃ§i, keskin ve detaylÄ±dÄ±r.

---

## 4. Model EÄŸitimi ve Mimari Detaylar

### 4.1. Generator Mimarisi (Ortak)
Her iki deneyde de Generator olarak **U-Net** kullanÄ±lmÄ±ÅŸtÄ±r. U-Net, gÃ¶rÃ¼ntÃ¼yÃ¼ sÄ±kÄ±ÅŸtÄ±rÄ±p (Encoder) tekrar geniÅŸletirken (Decoder), aradaki detay kaybÄ±nÄ± Ã¶nlemek iÃ§in Ã¶zel bir yapÄ± kullanÄ±r.
* **Encoder (Downsampling):** `Conv2D`, `BatchNormalization` ve `LeakyReLU` katmanlarÄ± ile gÃ¶rÃ¼ntÃ¼ 256x256 boyutundan 1x1 boyutuna sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±r (Feature Extraction).
* **Decoder (Upsampling):** `Conv2DTranspose` ile gÃ¶rÃ¼ntÃ¼ tekrar geniÅŸletilir. Ä°lk 3 katmanda Dropout uygulanarak overfitting engellenir.
* **Skip Connections (AtlamalÄ± BaÄŸlantÄ±lar):** Encoder katmanÄ±ndaki yapÄ±sal detaylar (kenarlar), darboÄŸaz (bottleneck) katmanÄ±nda kaybolmamalarÄ± iÃ§in doÄŸrudan Decoder katmanÄ±na kopyalanÄ±r (`Concatenate`). Bu, taslaÄŸÄ±n ÅŸeklinin korunmasÄ±nÄ± saÄŸlar.

### 4.2. Discriminator Mimarisi (PatchGAN)
Sadece GAN aÅŸamasÄ±nda kullanÄ±lmÄ±ÅŸtÄ±r.
* GiriÅŸ olarak hem "Hedef Resim" hem de "Ãœretilen/GerÃ§ek Resim" Ã§iftini alÄ±r.
* GÃ¶rÃ¼ntÃ¼yÃ¼ $30 \times 30$ boyutunda yamalara bÃ¶ler.
* Her yama iÃ§in "GerÃ§ek" veya "Sahte" kararÄ± verir. Bu, modelin resmin geneline deÄŸil, ince detaylarÄ±na odaklanmasÄ±nÄ± saÄŸlar.

### 4.3. KayÄ±p FonksiyonlarÄ± (Loss Functions)
GAN eÄŸitimi sÄ±rasÄ±nda karma bir kayÄ±p fonksiyonu minimize edilmiÅŸtir:

$$Total Loss = Loss_{GAN} + (\lambda \times Loss_{L1})$$

1.  **Adversarial Loss:** Generator'Ä±n Discriminator'Ä± kandÄ±rma baÅŸarÄ±sÄ±. (GerÃ§ekÃ§ilik saÄŸlar).
2.  **L1 Loss:** Ãœretilen resmin orijinal fotoÄŸrafla piksel bazÄ±nda eÅŸleÅŸmesi. (Renk ve iÃ§erik doÄŸruluÄŸu saÄŸlar).
    * $\lambda$ (Lambda) katsayÄ±sÄ±, L1 kaybÄ±nÄ±n etkisini artÄ±rmak iÃ§in 100 olarak belirlenmiÅŸtir.

### 4.4. EÄŸitim Parametreleri
* **Platform:** Kaggle (Tesla P100 GPU)
* **Optimizer:** Adam ($\beta_1 = 0.5$, Learning Rate = 0.0002)
* **Batch Size:** 1 (Pix2Pix mimarisi iÃ§in standart olan instance normalization etkisi).
* **SÃ¼re:** Modellerin yakÄ±nsamasÄ± ve loss deÄŸerlerinin stabilize olmasÄ± yaklaÅŸÄ±k 4-5 saat sÃ¼rmÃ¼ÅŸtÃ¼r.

---

## 5. KullanÄ±lan Teknolojiler ve AraÃ§lar

Projenin geliÅŸtirilmesinde aÅŸaÄŸÄ±daki kÃ¼tÃ¼phane ve araÃ§lar kullanÄ±lmÄ±ÅŸtÄ±r:

* **Python 3.9+:** Ana programlama dili.
* **TensorFlow & Keras:** Derin Ã¶ÄŸrenme modellerinin (U-Net, PatchGAN) oluÅŸturulmasÄ±, eÄŸitilmesi ve tensÃ¶r iÅŸlemleri.
* **Streamlit:** EÄŸitilen modelin son kullanÄ±cÄ±ya sunulmasÄ± iÃ§in interaktif web arayÃ¼zÃ¼ geliÅŸtirilmesi.
* **OpenCV (cv2):** GÃ¶rÃ¼ntÃ¼ okuma, gri tonlamaya Ã§evirme ve Ã¶n iÅŸleme (Canny Edge, Thresholding) iÅŸlemleri.
* **NumPy:** Matris operasyonlarÄ± ve veri manipÃ¼lasyonu.
* **Matplotlib:** EÄŸitim sÄ±rasÄ±ndaki Loss grafiklerinin gÃ¶rselleÅŸtirilmesi.
* **Gdown:** BÃ¼yÃ¼k boyutlu model aÄŸÄ±rlÄ±klarÄ±nÄ±n Google Drive Ã¼zerinden Ã§alÄ±ÅŸma zamanÄ±nda (runtime) indirilmesi.
* **Pillow (PIL):** GÃ¶rÃ¼ntÃ¼ formatÄ± dÃ¶nÃ¼ÅŸÃ¼mleri.

---

## 6. Proje DokÃ¼mantasyonu ve Dosya YapÄ±sÄ±

Proje dosyalarÄ±, yeniden Ã¼retilebilirlik (reproducibility) ilkesine uygun olarak organize edilmiÅŸtir.

```text
Landscape-Sketch-to-Paint/
â”œâ”€â”€ app.py                     # Streamlit web arayÃ¼zÃ¼ ana dosyasÄ±
â”œâ”€â”€ requirements.txt           # Gerekli Python kÃ¼tÃ¼phaneleri
â”œâ”€â”€ style_utils.py             # ArayÃ¼z iÃ§in CSS ve tasarÄ±m kodlarÄ±
â”œâ”€â”€ src/                       # Kaynak Kodlar
â”‚   â”œâ”€â”€ model.py               # U-Net ve GAN mimari tanÄ±mlarÄ± (Generator/Discriminator)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ notebooks/                 # Model EÄŸitim SÃ¼reÃ§leri (KanÄ±t DosyalarÄ±)
â”‚   â”œâ”€â”€ Training_UNet.ipynb        # 1. AÅŸama: U-Net Denemeleri ve SonuÃ§larÄ±
â”‚   â””â”€â”€ Training_Pix2Pix_GAN.ipynb # 2. AÅŸama: Final GAN Modeli EÄŸitimi
â”œâ”€â”€ examples/                  # Test iÃ§in Ã¶rnek taslak gÃ¶rselleri
â””â”€â”€ models/                    # (Otomatik iner) EÄŸitilmiÅŸ aÄŸÄ±rlÄ±k dosyalarÄ±

````


## 7. Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
Projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsiniz:

1.Depoyu klonlayÄ±n:

````bash
git clone [https://github.com/Fatmanurkntr/Landscape-Sketch-to-Paint.git](https://github.com/Fatmanurkntr/Landscape-Sketch-to-Paint.git)
cd Landscape-Sketch-to-Paint

````

2.Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:

````bash
pip install -r requirements.txt
````
3.UygulamayÄ± baÅŸlatÄ±n:

````bash
streamlit run app.py
````

## 8. Referanslar

1.Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. Proceedings of the IEEE conference on computer vision and pattern recognition.

2.Ronneberger, O., Fischer, P., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. International Conference on Medical Image Computing and Computer-Assisted Intervention.

3.Goodfellow, I., et al. (2014). Generative adversarial nets. Advances in neural information processing systems.



